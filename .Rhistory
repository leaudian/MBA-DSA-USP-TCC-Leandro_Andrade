nn$result.matrix[1,1]
nn$call
nn$linear.output
nn$weights
nn$generalized.weights
?err.fct
?`neuralnet-package`::err.fct
?`neuralnet::err.fct
?neuralnet::err.fct
#Ajustes iniciais
library(neuralnet)
set.seed(0)
data <- Boston
#Ajustes iniciais
library(neuralnet)
set.seed(0)
data <- Boston
#Normalização das variáveis
max_data <- apply(data, 2, max)
#Ajustes iniciais
library("MASS")
library("rpart")
library("neuralnet")
set.seed(0)
data <- Boston
#install.packages("MASS")
library("MASS")
library("rpart")
set.seed(0)
#Baixa os dados
data <- Boston
#Ajustes iniciais
library("MASS")
library("rpart")
library("neuralnet")
set.seed(0)
data <- Boston
#Funções de ativação
softplus<-function(x) log(1+exp(x))
relu<-function(x) ifelse(x>=0,x,0)
#"logistic"
#softplus
#relu
#*******************************#
#*******************************#
#*******************************#
lr<-0.01
neuronios<-5
camadas<-3
rede<-rep(neuronios,each=camadas)
fx<-"relu"
#neuronios_camadas<-c(5,4,3,2)
#data <- Boston
#n<-names(data)
#f<-as.formula(paste("Private~",paste(n[!n%in%"Private"],collapse = "+")))
#*******************************#
#*******************************#
#*******************************#
#Normalização das variáveis
max_data <- apply(data, 2, max)
min_data <- apply(data, 2, min)
scaled <- scale(data,center = min_data, scale = max_data - min_data)
#Definição do grupo de treine e teste
index = sample(1:nrow(data),round(0.70*nrow(data)))
data_treino <- as.data.frame(scaled[index,])
data_teste <- as.data.frame(scaled[-index,])
rm(scaled,max_data,min_data,index)
#Aplicação da rede neural
nn <- neuralnet(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+black+lstat,
data=data_treino,
hidden=c(5,4,3),
act.fct = relu,
learningrate = lr)
pr.nn <- compute(nn,data_treino[,1:13])
pr.nn_ <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test.r <- (data_teste$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
MSE_nn <- mean((pr.nn_ - test.r)^2)
rm(pr.nn,pr.nn_,test.r)
#Ajustes iniciais
library("MASS")
library("rpart")
library("neuralnet")
set.seed(0)
data <- Boston
#Funções de ativação
softplus<-function(x) log(1+exp(x))
relu<-function(x) ifelse(x>=0,x,0)
#"logistic"
#softplus
#relu
#*******************************#
#*******************************#
#*******************************#
lr<-0.01
neuronios<-5
camadas<-3
rede<-rep(neuronios,each=camadas)
fx<-"relu"
#neuronios_camadas<-c(5,4,3,2)
#data <- Boston
#n<-names(data)
#f<-as.formula(paste("Private~",paste(n[!n%in%"Private"],collapse = "+")))
#*******************************#
#*******************************#
#*******************************#
#Normalização das variáveis
max_data <- apply(data, 2, max)
min_data <- apply(data, 2, min)
scaled <- scale(data,center = min_data, scale = max_data - min_data)
#Definição do grupo de treine e teste
index = sample(1:nrow(data),round(0.70*nrow(data)))
data_treino <- as.data.frame(scaled[index,])
data_teste <- as.data.frame(scaled[-index,])
rm(scaled,max_data,min_data,index)
#Aplicação da rede neural
nn <- neuralnet(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+black+lstat,
data=data_treino,
hidden=c(5,4,3),
act.fct = "logistic",
learningrate = lr)
pr.nn <- compute(nn,data_treino[,1:13])
pr.nn_ <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test.r <- (data_teste$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
MSE_nn <- mean((pr.nn_ - test.r)^2)
rm(pr.nn,pr.nn_,test.r)
#Ajustes iniciais
library("MASS")
library("rpart")
library("neuralnet")
set.seed(0)
data <- Boston
#Funções de ativação
softplus<-function(x) log(1+exp(x))
relu<-function(x) ifelse(x>=0,x,0)
#"logistic"
#softplus
#relu
#*******************************#
#*******************************#
#*******************************#
lr<-0.01
neuronios<-5
camadas<-3
rede<-rep(neuronios,each=camadas)
fx<-"logistic"
#neuronios_camadas<-c(5,4,3,2)
#data <- Boston
#n<-names(data)
#f<-as.formula(paste("Private~",paste(n[!n%in%"Private"],collapse = "+")))
#*******************************#
#*******************************#
#*******************************#
#Normalização das variáveis
max_data <- apply(data, 2, max)
min_data <- apply(data, 2, min)
scaled <- scale(data,center = min_data, scale = max_data - min_data)
#Definição do grupo de treine e teste
index = sample(1:nrow(data),round(0.70*nrow(data)))
data_treino <- as.data.frame(scaled[index,])
data_teste <- as.data.frame(scaled[-index,])
rm(scaled,max_data,min_data,index)
#Aplicação da rede neural
nn <- neuralnet(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+black+lstat,
data=data_treino,
hidden=c(5,4,3),
act.fct = "logistic",
learningrate = lr)
pr.nn <- compute(nn,data_treino[,1:13])
pr.nn_ <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test.r <- (data_teste$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
MSE_nn <- mean((pr.nn_ - test.r)^2)
rm(pr.nn,pr.nn_,test.r)
#Ajustes iniciais
library("MASS")
library("rpart")
library("neuralnet")
set.seed(0)
data <- Boston
#Funções de ativação
softplus<-function(x) log(1+exp(x))
relu<-function(x) ifelse(x>=0,x,0)
#"logistic"
#softplus
#relu
#*******************************#
#*******************************#
#*******************************#
lr<-0.01
neuronios<-5
camadas<-3
rede<-rep(neuronios,each=camadas)
fx<-"logistic"
#neuronios_camadas<-c(5,4,3,2)
#data <- Boston
#n<-names(data)
#f<-as.formula(paste("Private~",paste(n[!n%in%"Private"],collapse = "+")))
#*******************************#
#*******************************#
#*******************************#
#Normalização das variáveis
max_data <- apply(data, 2, max)
min_data <- apply(data, 2, min)
scaled <- scale(data,center = min_data, scale = max_data - min_data)
#Definição do grupo de treine e teste
index = sample(1:nrow(data),round(0.70*nrow(data)))
data_treino <- as.data.frame(scaled[index,])
data_teste <- as.data.frame(scaled[-index,])
rm(scaled,max_data,min_data,index)
#Aplicação da rede neural
nn <- neuralnet(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+black+lstat,
data=data_treino,
hidden=c(5,4,3),
act.fct = fx,
learningrate = lr)
pr.nn <- compute(nn,data_treino[,1:13])
pr.nn_ <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test.r <- (data_teste$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
MSE_nn <- mean((pr.nn_ - test.r)^2)
rm(pr.nn,pr.nn_,test.r)
#Ajustes iniciais
library("MASS")
library("rpart")
library("neuralnet")
set.seed(0)
data <- Boston
#Funções de ativação
softplus<-function(x) log(1+exp(x))
relu<-function(x) ifelse(x>=0,x,0)
#"logistic"
#softplus
#relu
#*******************************#
#*******************************#
#*******************************#
lr<-0.01
neuronios<-5
camadas<-3
rede<-rep(neuronios,each=camadas)
fx<-"relu"
#neuronios_camadas<-c(5,4,3,2)
#data <- Boston
#n<-names(data)
#f<-as.formula(paste("Private~",paste(n[!n%in%"Private"],collapse = "+")))
#*******************************#
#*******************************#
#*******************************#
#Normalização das variáveis
max_data <- apply(data, 2, max)
min_data <- apply(data, 2, min)
scaled <- scale(data,center = min_data, scale = max_data - min_data)
#Definição do grupo de treine e teste
index = sample(1:nrow(data),round(0.70*nrow(data)))
data_treino <- as.data.frame(scaled[index,])
data_teste <- as.data.frame(scaled[-index,])
rm(scaled,max_data,min_data,index)
#Aplicação da rede neural
nn <- neuralnet(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+black+lstat,
data=data_treino,
hidden=c(5,4,3),
act.fct = fx,
learningrate = lr)
pr.nn <- compute(nn,data_treino[,1:13])
pr.nn_ <- pr.nn$net.result*(max(data$medv)-min(data$medv))+min(data$medv)
test.r <- (data_teste$medv)*(max(data$medv)-min(data$medv))+min(data$medv)
MSE_nn <- mean((pr.nn_ - test.r)^2)
rm(pr.nn,pr.nn_,test.r)
rm(MSE_nn,nn,data,data_teste,data_treino)
fx<-"relu"
fx<-function(x) log(1+exp(x))
for (i in 1:3){
if (i==1){funcao_ativacao<-"logistic"} #sigmoide
if (i==2){funcao_ativacao<-function(x) log(1+exp(x))} #softplus
if (i==3){funcao_ativacao<-function(x) ifelse(x>=0,x,0)} #relu
i<-i+1
}
View(funcao_ativacao)
for (i in 1:2){
if (i==1){funcao_ativacao<-"logistic"} #sigmoide
if (i==2){funcao_ativacao<-function(x) log(1+exp(x))} #softplus
if (i==3){funcao_ativacao<-function(x) ifelse(x>=0,x,0)} #relu
i<-i+1
}
View(funcao_ativacao)
for (i in 0:1){
if (i==1){funcao_ativacao<-"logistic"} #sigmoide
if (i==2){funcao_ativacao<-function(x) log(1+exp(x))} #softplus
if (i==3){funcao_ativacao<-function(x) ifelse(x>=0,x,0)} #relu
i<-i+1
}
#----------------------------------------#
#----------Carregar bibliotecas----------#
#----------------------------------------#
library(dplyr)
library("tidyverse")
library(openxlsx)
library(readxl)
#library(MASS)
#library(ISLR)
#library(mlbench)
library(neuralnet)
library(rpart)
#----------------------------------------#
#--------Carregar banco de dados---------#
#----------------------------------------#
#Caminho
Caminho=paste0(getwd(),"/")
#Carregar arquivo resultante da etapa anterior
BD_Amostra<-read_excel(paste0(Caminho,"BD_Amostra_Backup.xlsx"))
#Remoção das variáveis que não farão parte das Redes Neurais
BD_Neural_Networks<-select(BD_Amostra,everything(),
-Estado_man,
-Estado_vis,
-rodada,
-idade_media_titular_man,
-idade_media_titular_vis,
-Aprov_3_man,
-Aprov_5_man,
-Aprov_1_vis,
-Aprov_3_vis,
-Finalista_Copa_Brasil_vis,
-Finalista_Estadual_man,
-Finalista_Estadual_vis)
rm(BD_Amostra)
#Alterando a ordem das colunas no dataset (Batch / Var de Saída / Var Cat / Var Cont)
BD_Neural_Networks<-BD_Neural_Networks %>%
relocate(Finalista_Brasileiro_vis,.after = time_vis) %>%
relocate(Finalista_Brasileiro_man,.after = time_vis) %>%
relocate(Finalista_Copa_Brasil_man,.after = time_vis) %>%
relocate(Libertadores_vis,.after = time_vis) %>%
relocate(Libertadores_man,.after = time_vis)
#----------------------------------------#
#--Normalização das variáveis contínuas--#
#----------------------------------------#
BD_NN_Normalizada<-BD_Neural_Networks %>%
mutate(gols_man=(gols_man-min(gols_man))/(max(gols_man-min(gols_man)))) %>%
mutate(gols_vis=(gols_vis-min(gols_vis))/(max(gols_vis)-min(gols_vis))) %>%
mutate(ano_campeonato=(ano_campeonato-min(ano_campeonato))/(max(ano_campeonato)-min(ano_campeonato))) %>%
mutate(colocacao_man=(colocacao_man-min(colocacao_man))/(max(colocacao_man)-min(colocacao_man))) %>%
mutate(colocacao_vis=(colocacao_vis-min(colocacao_vis))/(max(colocacao_vis)-min(colocacao_vis))) %>%
mutate(med_acum_gols_m_man=(med_acum_gols_m_man-min(med_acum_gols_m_man))/(max(med_acum_gols_m_man)-min(med_acum_gols_m_man))) %>%
mutate(med_acum_gols_m_vis=(med_acum_gols_m_vis-min(med_acum_gols_m_vis))/(max(med_acum_gols_m_vis)-min(med_acum_gols_m_vis))) %>%
mutate(med_acum_gols_s_man=(med_acum_gols_s_man-min(med_acum_gols_s_man))/(max(med_acum_gols_s_man)-min(med_acum_gols_s_man))) %>%
mutate(med_acum_gols_s_vis=(med_acum_gols_s_vis-min(med_acum_gols_s_vis))/(max(med_acum_gols_s_vis)-min(med_acum_gols_s_vis)))
View(BD_NN_Normalizada)
teste<-BD_NN_Normalizada %>% filter(BD_NN_Normalizada$Batch_Fold_Index=="A")
View(teste)
teste<-BD_NN_Normalizada %>% filter(!BD_NN_Normalizada$Batch_Fold_Index=="A")
View(teste)
for(c in 1:3){
c<-c+1
}
for(c in 1:3)
{c<-c+1}
rm(c)
for(c in 1:3)
{c<-c+1}
rm(c)
View(BD_NN_Normalizada)
write.xlsx(BD_Neural_Networks, "BD_NN_Normalizada_Backup.xlsx",sheetName = "BD_NN_Normalizada")
library(caret)
library(lattice)
library(ggplot2)
library(neuralnet)
dataset_iris = iris
dataset_iris = cbind(dataset_iris,dataset_iris$Species=='setosa')
dataset_iris = cbind(dataset_iris,dataset_iris$Species=='versicolor')
dataset_iris = cbind(dataset_iris,dataset_iris$Species=='virginica')
names(dataset_iris)[6] <- 'setosa'
names(dataset_iris)[7] <- 'versicolor'
names(dataset_iris)[8] <- 'virginica'
particao = createDataPartition(1:dim(dataset_iris)[1],p=.7)
dataset_treino = dataset_iris[particao$Resample1,]
dataset_teste = dataset_iris[- particao$Resample1,]
modelo = neuralnet( setosa  + versicolor  +  virginica  ~
Sepal.Length +
Sepal.Width +
Petal.Length +
Petal.Width ,
dataset_treino,
hidden=c(5,4),
act.fct = "logistic")
plot(modelo, rep="best")
dataset_teste[25,1:5]
teste = compute(modelo,dataset_teste[25,1:4])
library(caret)
library(lattice)
library(ggplot2)
library(neuralnet)
dataset_iris = iris
dataset_iris = cbind(dataset_iris,dataset_iris$Species=='setosa')
dataset_iris = cbind(dataset_iris,dataset_iris$Species=='versicolor')
dataset_iris = cbind(dataset_iris,dataset_iris$Species=='virginica')
names(dataset_iris)[6] <- 'setosa'
names(dataset_iris)[7] <- 'versicolor'
names(dataset_iris)[8] <- 'virginica'
particao = createDataPartition(1:dim(dataset_iris)[1],p=.7)
dataset_treino = dataset_iris[particao$Resample1,]
dataset_teste = dataset_iris[- particao$Resample1,]
modelo = neuralnet( setosa  + versicolor  +  virginica  ~
Sepal.Length +
Sepal.Width +
Petal.Length +
Petal.Width ,
dataset_treino,
hidden=c(5,4),
act.fct = "logistic")
plot(modelo, rep="best")
dataset_teste[25,1:5]
View(dataset_treino)
#----------------------------------------#
#----------Carregar bibliotecas----------#
#----------------------------------------#
library(dplyr)
library("tidyverse")
library(openxlsx)
library(readxl)
#library(MASS)
#library(ISLR)
#library(mlbench)
library(neuralnet)
library(rpart)
#----------------------------------------#
#--------Carregar banco de dados---------#
#----------------------------------------#
#Caminho
Caminho=paste0(getwd(),"/")
#Carregar arquivo resultante da etapa anterior
BD_Amostra<-read_excel(paste0(Caminho,"BD_Amostra_Backup.xlsx"))
#Remoção das variáveis que não farão parte das Redes Neurais
BD_Neural_Networks<-select(BD_Amostra,everything(),
-Estado_man,
-Estado_vis,
-rodada,
-idade_media_titular_man,
-idade_media_titular_vis,
-Aprov_3_man,
-Aprov_5_man,
-Aprov_1_vis,
-Aprov_3_vis,
-Finalista_Copa_Brasil_vis,
-Finalista_Estadual_man,
-Finalista_Estadual_vis)
rm(BD_Amostra)
#Alterando a ordem das colunas no dataset (Batch / Var de Saída / Var Cat / Var Cont)
BD_Neural_Networks<-BD_Neural_Networks %>%
relocate(Finalista_Brasileiro_vis,.after = time_vis) %>%
relocate(Finalista_Brasileiro_man,.after = time_vis) %>%
relocate(Finalista_Copa_Brasil_man,.after = time_vis) %>%
relocate(Libertadores_vis,.after = time_vis) %>%
relocate(Libertadores_man,.after = time_vis)
#----------------------------------------#
#--Normalização das variáveis contínuas--#
#----------------------------------------#
BD_NN_Normalizada<-BD_Neural_Networks %>%
mutate(gols_man=(gols_man-min(gols_man))/(max(gols_man-min(gols_man)))) %>%
mutate(gols_vis=(gols_vis-min(gols_vis))/(max(gols_vis)-min(gols_vis))) %>%
mutate(ano_campeonato=(ano_campeonato-min(ano_campeonato))/(max(ano_campeonato)-min(ano_campeonato))) %>%
mutate(colocacao_man=(colocacao_man-min(colocacao_man))/(max(colocacao_man)-min(colocacao_man))) %>%
mutate(colocacao_vis=(colocacao_vis-min(colocacao_vis))/(max(colocacao_vis)-min(colocacao_vis))) %>%
mutate(med_acum_gols_m_man=(med_acum_gols_m_man-min(med_acum_gols_m_man))/(max(med_acum_gols_m_man)-min(med_acum_gols_m_man))) %>%
mutate(med_acum_gols_m_vis=(med_acum_gols_m_vis-min(med_acum_gols_m_vis))/(max(med_acum_gols_m_vis)-min(med_acum_gols_m_vis))) %>%
mutate(med_acum_gols_s_man=(med_acum_gols_s_man-min(med_acum_gols_s_man))/(max(med_acum_gols_s_man)-min(med_acum_gols_s_man))) %>%
mutate(med_acum_gols_s_vis=(med_acum_gols_s_vis-min(med_acum_gols_s_vis))/(max(med_acum_gols_s_vis)-min(med_acum_gols_s_vis)))
write.xlsx(BD_Neural_Networks, "BD_NN_Normalizada_Backup.xlsx",sheetName = "BD_NN_Normalizada")
View(BD_NN_Normalizada)
View(BD_NN_Normalizada)
write.xlsx(BD_NN_Normalizada, "BD_NN_Normalizada_Backup.xlsx",sheetName = "BD_NN_Normalizada")
#Ajustes iniciais
library("MASS")
library("rpart")
library("neuralnet")
set.seed(0)
data <- Boston
#Funções de ativação
softplus<-function(x) log(1+exp(x))
relu<-function(x) ifelse(x>=0,x,0)
#"logistic"
#softplus
#relu
#*******************************#
#*******************************#
#*******************************#
lr<-0.01
neuronios<-5
camadas<-3
rede<-rep(neuronios,each=camadas)
fx<-function(x) log(1+exp(x))
#neuronios_camadas<-c(5,4,3,2)
#data <- Boston
#n<-names(data)
#f<-as.formula(paste("Private~",paste(n[!n%in%"Private"],collapse = "+")))
#*******************************#
#*******************************#
#*******************************#
#Normalização das variáveis
max_data <- apply(data, 2, max)
min_data <- apply(data, 2, min)
scaled <- scale(data,center = min_data, scale = max_data - min_data)
#Definição do grupo de treine e teste
index = sample(1:nrow(data),round(0.70*nrow(data)))
data_treino <- as.data.frame(scaled[index,])
data_teste <- as.data.frame(scaled[-index,])
rm(scaled,max_data,min_data,index)
#Aplicação da rede neural
nn <- neuralnet(medv~crim+zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+black+lstat,
data=data_treino,
hidden=c(5,4,3),
act.fct = fx,
learningrate = lr)
pr.nn <- compute(nn,data_teste[,1:13])
pr.nn <- compute(nn,data_treino[,1:13])
?compute
